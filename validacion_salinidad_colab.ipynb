{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Validación de salinidad (ECe) con índices Sentinel-2\n",
        "\n",
        "Este cuaderno carga puntos con índices (desde GEE) y mediciones de ECe, entrena modelos,\n",
        "aplica **validación espacial por bloques**, calcula métricas (R², RMSE, MAE, RPD) y prepara\n",
        "coeficientes/expresiones para aplicar el modelo en GEE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Si usas Colab, puedes necesitar instalar paquetes. Descomenta si es necesario.\n",
        "# %pip install -q scikit-learn pandas matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GroupKFold, cross_val_predict\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Rutas de ejemplo (sube tus archivos o monta Drive)\n",
        "indices_path = r\"./dummy_ece_indices.csv\"  # Reemplaza por 'indices_pts.csv' exportado desde GEE\n",
        "field_path = r\"./dummy_ece_indices.csv\"    # Reemplaza por tu 'ece_terreno.csv' real cuando lo tengas\n",
        "\n",
        "indices_df = pd.read_csv(indices_path)\n",
        "field_df = pd.read_csv(field_path)\n",
        "\n",
        "# En tu flujo real, 'indices_df' y 'field_df' serían distintos; aquí usamos el dummy para demo.\n",
        "# Supón que comparten 'id' o ('lon','lat','date','depth_cm'). Haremos un merge por id para simplicidad.\n",
        "df = pd.merge(indices_df, field_df[['id','ECe_dSm']], on='id', suffixes=('', '_y'))\n",
        "df = df.rename(columns={'ECe_dSm': 'ECe'})\n",
        "df = df[['id','lon','lat','depth_cm','date','NDVI','NDMI','SI','ECe']].dropna().copy()\n",
        "\n",
        "print(\"Filas:\", len(df))\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Asignar bloques espaciales gruesos para validación sin fuga espacial\n",
        "def make_blocks(lon, lat, size=0.001):  # ~100 m aprox; ajusta según AOI\n",
        "    bx = np.floor((lon - lon.min()) / size).astype(int)\n",
        "    by = np.floor((lat - lat.min()) / size).astype(int)\n",
        "    return (bx * 10_000 + by).astype(int)\n",
        "\n",
        "df['block_id'] = make_blocks(df['lon'].values, df['lat'].values, size=0.0015)\n",
        "\n",
        "features = ['NDVI','NDMI','SI']\n",
        "target = 'ECe'\n",
        "\n",
        "X = df[features].values\n",
        "y = df[target].values\n",
        "groups = df['block_id'].values\n",
        "\n",
        "# Modelos a probar\n",
        "models = {\n",
        "    'Linear': Pipeline([('scaler', StandardScaler()), ('model', LinearRegression())]),\n",
        "    'Ridge':  Pipeline([('scaler', StandardScaler()), ('model', Ridge(alpha=1.0))]),\n",
        "    'RF':     Pipeline([('model', RandomForestRegressor(n_estimators=300, random_state=0, n_jobs=-1))])\n",
        "}\n",
        "\n",
        "def rpd(y_true, y_pred):\n",
        "    sd = np.std(y_true, ddof=1)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    return sd / rmse if rmse > 0 else np.nan\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "\n",
        "results = []\n",
        "preds_store = {{}}\n",
        "for name, pipe in models.items():\n",
        "    yhat = cross_val_predict(pipe, X, y, cv=gkf.split(X, y, groups=groups), n_jobs=-1)\n",
        "    R2 = r2_score(y, yhat)\n",
        "    RMSE = np.sqrt(mean_squared_error(y, yhat))\n",
        "    MAE = mean_absolute_error(y, yhat)\n",
        "    RPD = rpd(y, yhat)\n",
        "    results.append((name, R2, RMSE, MAE, RPD))\n",
        "    preds_store[name] = yhat\n",
        "\n",
        "res_df = pd.DataFrame(results, columns=['Model','R2','RMSE','MAE','RPD']).sort_values('R2', ascending=False)\n",
        "res_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Gráfico Observado vs Predicho para el mejor modelo\n",
        "best = res_df.iloc[0]['Model']\n",
        "yhat = preds_store[best]\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.scatter(y, yhat, alpha=0.6)\n",
        "mn, mx = min(y.min(), yhat.min()), max(y.max(), yhat.max())\n",
        "plt.plot([mn, mx], [mn, mx])\n",
        "plt.xlabel('ECe observado (dS/m)')\n",
        "plt.ylabel('ECe predicho (dS/m)')\n",
        "plt.title(f'Observed vs Predicted - {best}')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Entrena el mejor modelo en todos los datos y exporta coeficientes si es lineal\n",
        "best = res_df.iloc[0]['Model']\n",
        "pipe = models[best]\n",
        "pipe.fit(X, y)\n",
        "\n",
        "if best in ('Linear','Ridge'):\n",
        "    scaler = pipe.named_steps['scaler']\n",
        "    model = pipe.named_steps['model']\n",
        "    coefs = dict(zip(['NDVI','NDMI','SI'], model.coef_))\n",
        "    intercept = model.intercept_\n",
        "    print(\"Coeficientes (sobre variables estandarizadas):\", coefs)\n",
        "    print(\"Intercept:\", intercept)\n",
        "\n",
        "    # Para aplicar en GEE, calcula fórmula explícita en términos originales:\n",
        "    mu = dict(zip(['NDVI','NDMI','SI'], scaler.mean_))\n",
        "    sd = dict(zip(['NDVI','NDMI','SI'], scaler.scale_))\n",
        "\n",
        "    # ECe = b0 + sum(bi * (Xi - mu_i)/sd_i)\n",
        "    # Reescribe como ECe = A0 + a_NDVI*NDVI + a_NDMI*NDMI + a_SI*SI\n",
        "    a = {k: (coefs[k]/sd[k]) for k in coefs}\n",
        "    A0 = intercept - sum((coefs[k]*mu[k]/sd[k]) for k in coefs)\n",
        "    print(\"Expresión no estandarizada:\")\n",
        "    print(\"ECe = {:.6f} + {:.6f}*NDVI + {:.6f}*NDMI + {:.6f}*SI\".format(A0, a['NDVI'], a['NDMI'], a['SI']))\n",
        "\n",
        "else:\n",
        "    # Para RF, la aplicación por pixeles es más cómoda en Python raster o en GEE con TF/EE (no cubierto aquí).\n",
        "    if hasattr(pipe.named_steps['model'], 'feature_importances_'):\n",
        "        fi = dict(zip(['NDVI','NDMI','SI'], pipe.named_steps['model'].feature_importances_))\n",
        "        print(\"Importancias (RF):\", fi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Clasificación por umbrales de ECe (ajusta a tu cultivo/contexto)\n",
        "# Ejemplo: <2 (baja), 2-4 (leve), 4-8 (moderada), 8-16 (alta), >16 (extrema)\n",
        "bins = [-np.inf, 2, 4, 8, 16, np.inf]\n",
        "labels = ['baja','leve','moderada','alta','extrema']\n",
        "best = res_df.iloc[0]['Model']\n",
        "yhat = preds_store[best]\n",
        "classes = pd.cut(yhat, bins=bins, labels=labels)\n",
        "\n",
        "pd.DataFrame({'ECe_obs': y, 'ECe_pred': yhat, 'class_pred': classes}).head()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}